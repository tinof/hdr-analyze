#!/usr/bin/env python3
"""
mkvdolby.py - Convert HDR10/HDR10+ videos to Dolby Vision format
A refactored and enhanced Python script for accurate and controlled conversions.
"""

import os
import sys
import json
import shutil
import subprocess
import time
import re
import atexit
import glob
import argparse
from enum import Enum, auto
from typing import List, Dict, Any, Optional


# ANSI color codes
class Colors:
    GREEN = "\033[32m"
    RED = "\033[31m"
    YELLOW = "\033[33m"
    RESET = "\033[0m"


def print_color(color: str, text: str):
    """Print colored text to the console."""
    color_map = {
        "green": Colors.GREEN,
        "red": Colors.RED,
        "yellow": Colors.YELLOW,
    }
    color_code = color_map.get(color, "")
    print(f"{color_code}{text}{Colors.RESET}")


def run_command(command: List[str], log_file_path: str) -> bool:
    """
    Executes a command, logs its output, and checks for errors.

    Args:
        command: The command to execute as a list of strings.
        log_file_path: Path to the log file for stdout and stderr.

    Returns:
        True if the command succeeded, False otherwise.
    """
    try:
        with open(log_file_path, "w") as log_file:
            process = subprocess.run(
                command,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                check=True,
                text=True,
            )
        return process.returncode == 0
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        print_color("red", f"\nError executing command: {' '.join(command)}")
        print_color("red", f"See log for details: {log_file_path}")
        if os.path.exists(log_file_path):
            with open(log_file_path, "r") as log_file:
                print(log_file.read())
        else:
            print(f"Error details: {e}")
        return False


# Simple cache to avoid redundant mediainfo calls per file
MI_JSON_CACHE: Dict[str, Dict[str, Any]] = {}


def get_mediainfo_json_cached(input_file: str) -> Optional[Dict[str, Any]]:
    """Return mediainfo JSON for a file, using a simple in-memory cache."""
    path = os.path.abspath(input_file)
    if path in MI_JSON_CACHE:
        return MI_JSON_CACHE[path]
    try:
        mi_output = subprocess.check_output(
            ["mediainfo", "--Output=JSON", input_file], text=True
        )
        mi_json = json.loads(mi_output)
        MI_JSON_CACHE[path] = mi_json
        return mi_json
    except Exception:
        return None


class HdrFormat(Enum):
    """Enum for different HDR formats."""

    HDR10_PLUS = auto()
    HDR10_WITH_MEASUREMENTS = auto()
    HDR10_UNSUPPORTED = auto()
    HLG = auto()
    UNSUPPORTED = auto()


def check_dependencies():
    """Check base dependencies that are always required."""
    required_cmds = ["ffmpeg", "dovi_tool", "mediainfo", "mkvmerge"]
    all_found = True
    for cmd in required_cmds:
        if not shutil.which(cmd):
            print_color("red", f"Error: Required command '{cmd}' not found in PATH.")
            all_found = False

    if not all_found:
        sys.exit(1)


def ensure_command(cmd: str) -> bool:
    """Ensure a specific command exists in PATH."""
    if not shutil.which(cmd):
        print_color("red", f"Error: Required command '{cmd}' not found in PATH.")
        return False
    return True


def find_analyzer_executable() -> Optional[str]:
    """Return the analyzer executable name if found (supports alias 'hdranalyze')."""
    for name in ["hdr_analyzer_mvp", "hdranalyze"]:
        if shutil.which(name):
            return name
    return None


def run_hdr_analyzer(source_file: str, temp_dir: str) -> Optional[str]:
    """Run hdr_analyzer_mvp on a source file and return the measurements path."""
    exe = find_analyzer_executable()
    if not exe:
        print_color(
            "red",
            "Error: hdr_analyzer_mvp not found (try adding target/release to PATH or using alias 'hdranalyze').",
        )
        return None

    directory = os.path.dirname(os.path.abspath(source_file))
    base_no_ext = os.path.splitext(os.path.basename(source_file))[0]
    out_path = os.path.join(directory, f"{base_no_ext}_measurements.bin")
    log_path = os.path.join(temp_dir, "hdr_analyzer.log")
    cmd = [exe, source_file, "-o", out_path]
    if run_command(cmd, log_path) and os.path.isfile(out_path):
        print_color("green", f"Generated measurements: {os.path.basename(out_path)}")
        return os.path.abspath(out_path)
    print_color("red", "hdr_analyzer_mvp failed to create measurements. See log.")
    return None


def convert_hlg_to_pq(input_file: str, temp_dir: str, args: argparse.Namespace) -> Optional[str]:
    """Convert an HLG video to PQ (ST2084) for analysis and BL creation.

    Uses x265 with HDR10 signaling and embeds static metadata (ST 2086, MaxCLL/MaxFALL)
    derived from the original input when available.
    """
    base_no_ext = os.path.splitext(os.path.basename(input_file))[0]
    pq_path = os.path.join(temp_dir, f"{base_no_ext}_HLG_to_PQ.mkv")
    ffmpeg_log = os.path.join(temp_dir, "ffmpeg_hlg2pq.log")

    # Extract or default static metadata
    static_meta = get_static_metadata(input_file)
    max_dml = int(static_meta.get("max_dml", 1000))
    min_dml = float(static_meta.get("min_dml", 0.005))
    max_cll = int(static_meta.get("max_cll", 1000))
    max_fall = int(static_meta.get("max_fall", 400))

    # x265 master-display for BT.2020 primaries and D65 white point
    # Coordinates scaled by 50000, luminance scaled by 10000 (per x265 convention)
    master_display = (
        f"G(8500,39850)B(6550,2300)R(35400,14600)WP(15635,16450)"
        f"L({max_dml * 10000},{int(min_dml * 10000)})"
    )
    x265_params = (
        f"colorprim=bt2020:transfer=smpte2084:colormatrix=bt2020nc:"
        f"master-display={master_display}:max-cll={max_cll},{max_fall}:"
        f"hdr-opt=1:repeat-headers=1"
    )

    crf_value = str(getattr(args, "hlg_crf", 17))
    preset_value = str(getattr(args, "hlg_preset", "slow"))

    # Explicitly enforce limited range in and out
    vf = (
        "zscale=transferin=arib-std-b67:transfer=smpte2084:primaries=bt2020:"
        "matrix=bt2020nc:rangein=tv:range=tv,format=yuv420p10le"
    )

    cmd = [
        "ffmpeg",
        "-i",
        input_file,
        "-y",
        "-map",
        "0:v:0",
        "-an",
        "-sn",
        "-vf",
        vf,
        "-c:v",
        "libx265",
        "-preset",
        preset_value,
        "-crf",
        crf_value,
        "-pix_fmt",
        "yuv420p10le",
        "-profile:v",
        "main10",
        "-x265-params",
        x265_params,
        pq_path,
    ]
    print(
        f"HLG->PQ encode: CRF={crf_value}, preset={preset_value}, max_dml={max_dml}, "
        f"min_dml={min_dml}, MaxCLL/MaxFALL={max_cll}/{max_fall}"
    )
    if run_command(cmd, ffmpeg_log) and os.path.exists(pq_path):
        print_color("green", "Converted HLG to PQ successfully.")
        return os.path.abspath(pq_path)
    print_color("red", "HLG to PQ conversion failed. See log.")
    return None


def cleanup(temp_dir: str):
    """Clean up temporary files."""
    if os.path.exists(temp_dir):
        try:
            shutil.rmtree(temp_dir)
            print(f"Cleaned up temporary directory: {temp_dir}")
        except Exception as e:
            print_color(
                "yellow", f"Warning: Failed to clean up temporary directory: {e}"
            )


def find_measurements_file(input_file: str) -> Optional[str]:
    """Locate a madVR measurements file associated with the given input file.

    Supports common naming patterns:
    - measurements.bin (in the same directory)
    - <video>.mkv.measurements
    - <video>.measurements
    - <basename>.measurements (basename without extension)
    - <basename>_measurements.bin (new pattern for _measurements.bin files)

    Returns:
        Absolute path to the measurements file if found, otherwise None.
    """
    directory = os.path.dirname(os.path.abspath(input_file))
    base_with_ext = os.path.basename(input_file)
    base_no_ext = os.path.splitext(base_with_ext)[0]

    # Ordered candidates by preference
    candidates = [
        os.path.join(directory, "measurements.bin"),
        input_file + ".measurements",
        os.path.join(directory, base_with_ext + ".measurements"),
        os.path.join(directory, base_no_ext + ".measurements"),
        os.path.join(directory, base_no_ext + "_measurements.bin"),  # New pattern
    ]

    for candidate in candidates:
        if os.path.isfile(candidate):
            return os.path.abspath(candidate)

    # Fallback: look for a single *.measurements file that starts with the base name
    try:
        pattern_matches = [
            p for p in glob.glob(os.path.join(directory, "*.measurements"))
            if os.path.basename(p).startswith(base_no_ext)
        ]
        if len(pattern_matches) == 1 and os.path.isfile(pattern_matches[0]):
            return os.path.abspath(pattern_matches[0])
    except Exception:
        pass

    # Additional fallback: look for *_measurements.bin files that start with the base name
    try:
        pattern_matches = [
            p for p in glob.glob(os.path.join(directory, "*_measurements.bin"))
            if os.path.basename(p).startswith(base_no_ext)
        ]
        if len(pattern_matches) == 1 and os.path.isfile(pattern_matches[0]):
            return os.path.abspath(pattern_matches[0])
    except Exception:
        pass

    return None


def find_details_file(input_file: str) -> Optional[str]:
    """Locate a madVR Details.txt file associated with the given input file.

    Common patterns observed:
    - <video>_mkv_Details.txt
    - <video>_Details.txt
    - Any file ending with _mkv_Details.txt that starts with the video base name
    """
    directory = os.path.dirname(os.path.abspath(input_file))
    base_with_ext = os.path.basename(input_file)
    base_no_ext = os.path.splitext(base_with_ext)[0]

    candidates = [
        os.path.join(directory, f"{base_no_ext}_mkv_Details.txt"),
        os.path.join(directory, f"{base_no_ext}_Details.txt"),
    ]

    for candidate in candidates:
        if os.path.isfile(candidate):
            return os.path.abspath(candidate)

    try:
        pattern_matches = [
            p
            for p in glob.glob(os.path.join(directory, "*_mkv_Details.txt"))
            if os.path.basename(p).startswith(base_no_ext)
        ]
        if len(pattern_matches) == 1 and os.path.isfile(pattern_matches[0]):
            return os.path.abspath(pattern_matches[0])
    except Exception:
        pass

    return None


def _extract_number(value_str: str) -> Optional[float]:
    """Extract the first number in a string, handling comma decimals."""
    m = re.search(r"([0-9]+[.,]?[0-9]*)", value_str)
    if not m:
        return None
    try:
        return float(m.group(1).replace(",", "."))
    except ValueError:
        return None


def parse_madvr_details_static_values(details_path: str) -> Dict[str, Any]:
    """Parse key static values from madVR Details.txt.

    Extracts:
    - min_dml, max_dml from "Mastering display luminance: <min>/<max>"
    - max_cll (prefer "Calculated values after clipping" section if present,
      otherwise use "MaxCLL 100%")
    - max_fall (from "MaxFALL:")
    """
    result: Dict[str, Any] = {}
    try:
        with open(details_path, "r", encoding="utf-8", errors="ignore") as f:
            lines = f.readlines()

        in_after_clipping = False
        max_cll_after: Optional[int] = None
        max_cll_100: Optional[int] = None
        max_fall: Optional[int] = None
        min_dml: Optional[float] = None
        max_dml: Optional[float] = None

        for raw in lines:
            line = raw.strip()

            # Section detection
            if re.search(r"^Calculated values after clipping", line, re.IGNORECASE):
                in_after_clipping = True
                continue

            # Mastering display luminance
            m_lum = re.search(
                r"Mastering\s+display\s+luminance:\s*([0-9.,]+)\s*/\s*([0-9.,]+)",
                line,
                re.IGNORECASE,
            )
            if m_lum:
                min_val = _extract_number(m_lum.group(1))
                max_val = _extract_number(m_lum.group(2))
                if min_val is not None:
                    min_dml = float(min_val)
                if max_val is not None:
                    max_dml = float(max_val)
                continue

            # MaxCLL (100%)
            m_cll_100 = re.search(r"MaxCLL\s*100%\s*:\s*([0-9.,]+)", line, re.IGNORECASE)
            if m_cll_100 and max_cll_100 is None:
                num = _extract_number(m_cll_100.group(1))
                if num is not None:
                    max_cll_100 = int(num)
                continue

            # MaxCLL in the after-clipping section
            if in_after_clipping:
                m_cll_after = re.search(r"^MaxCLL\s*:\s*([0-9.,]+)$", line, re.IGNORECASE)
                if m_cll_after:
                    num = _extract_number(m_cll_after.group(1))
                    if num is not None:
                        max_cll_after = int(num)
                    continue

            # MaxFALL
            m_fall = re.search(r"^MaxFALL\s*:\s*([0-9.,]+)", line, re.IGNORECASE)
            if m_fall and max_fall is None:
                num = _extract_number(m_fall.group(1))
                if num is not None:
                    max_fall = int(num)
                continue

        if min_dml is not None:
            result["min_dml"] = min_dml
        if max_dml is not None:
            result["max_dml"] = int(max_dml)
        if max_fall is not None:
            result["max_fall"] = int(max_fall)
        # Prefer after-clipping MaxCLL if present, else 100% measured
        if max_cll_after is not None:
            result["max_cll"] = int(max_cll_after)
        elif max_cll_100 is not None:
            result["max_cll"] = int(max_cll_100)

    except Exception:
        # Silent fallback; caller will use defaults/mediainfo values
        return {}

    return result


def parse_madvr_details_for_trims(details_path: str) -> Optional[List[int]]:
    """Extract suggested trim target nits from Details.txt.

    Uses:
    - Real display peak nits (rounded to nearest 20/50) as a mid/high point
    - Maximum Target Nits as a high point (capped to reasonable values)
    - Always include a 100-nit trim
    Returns sorted unique integers, e.g., [100, 680, 1500].
    """
    try:
        with open(details_path, "r", encoding="utf-8", errors="ignore") as f:
            text = f.read()

        real_display_peak = None
        max_target_nits = None

        m_peak = re.search(r"Real\s+display\s+peak\s+nits:\s*([0-9.,]+)", text, re.IGNORECASE)
        if m_peak:
            v = _extract_number(m_peak.group(1))
            if v is not None and v > 0:
                real_display_peak = int(round(v))

        m_max = re.search(r"Maximum\s+Target\s+Nits:\s*([0-9.,]+)", text, re.IGNORECASE)
        if m_max:
            v = _extract_number(m_max.group(1))
            if v is not None and v > 0:
                max_target_nits = int(round(v))

        targets: List[int] = [100]
        if real_display_peak:
            targets.append(real_display_peak)
        if max_target_nits:
            targets.append(max_target_nits)

        # Clean and normalize
        targets = sorted({t for t in targets if 80 <= t <= 10000})
        if len(targets) >= 2:
            return targets
        return None
    except Exception:
        return None


def get_static_metadata(input_file: str) -> Dict[str, Any]:
    """
    Consolidates logic to extract static HDR metadata from a video file.
    It prioritizes mediainfo as the primary source.

    Args:
        input_file: The path to the input video file.

    Returns:
        A dictionary containing the extracted metadata or defaults.
    """
    metadata = {}
    defaults = {"max_dml": 1000, "min_dml": 0.0050, "max_cll": 1000, "max_fall": 400}

    try:
        # Use mediainfo as the primary source (cached)
        mi_json = get_mediainfo_json_cached(input_file) or {}
        video_track = next(
            (
                t
                for t in mi_json.get("media", {}).get("track", [])
                if t.get("@type") == "Video"
            ),
            None,
        )

        if video_track:
            # Mastering display metadata
            mdl = video_track.get("MasteringDisplay_Luminance")
            if mdl:
                max_dml_match = re.search(r"max: ([0-9.]+)", mdl)
                min_dml_match = re.search(r"min: ([0-9.]+)", mdl)
                if max_dml_match:
                    metadata["max_dml"] = int(float(max_dml_match.group(1)))
                if min_dml_match:
                    metadata["min_dml"] = float(min_dml_match.group(1))

            # Content light level metadata
            max_cll_str = video_track.get("MaxCLL", "0")
            max_fall_str = video_track.get("MaxFALL", "0")

            max_cll_match = re.search(r"([0-9.]+)", str(max_cll_str))
            max_fall_match = re.search(r"([0-9.]+)", str(max_fall_str))

            metadata["max_cll"] = (
                int(float(max_cll_match.group(1))) if max_cll_match else 0
            )
            metadata["max_fall"] = (
                int(float(max_fall_match.group(1))) if max_fall_match else 0
            )

    except (subprocess.SubprocessError, json.JSONDecodeError, FileNotFoundError) as e:
        print_color("yellow", f"Warning: Could not get metadata from mediainfo: {e}")

    # Supplement with madVR Details.txt if available
    details_path = find_details_file(input_file)
    if details_path:
        details_values = parse_madvr_details_static_values(details_path)
        if details_values:
            # Merge, preferring details values when present
            metadata.update({k: v for k, v in details_values.items() if v is not None})
            print(
                f"Supplemented static metadata from Details.txt: "
                f"{ {k: metadata[k] for k in ['max_dml','min_dml','max_cll','max_fall'] if k in metadata} }"
            )

    # Validate and fill with defaults if necessary
    final_metadata = defaults.copy()
    missing_keys = []
    for key in defaults:
        if metadata.get(key):
            final_metadata[key] = metadata[key]
        else:
            missing_keys.append(key.upper())

    if missing_keys:
        print_color(
            "yellow",
            f"Warning: Missing metadata for: {', '.join(missing_keys)}. Using defaults.",
        )
        print_color(
            "yellow",
            f"Default values used: MaxDML={defaults['max_dml']}, MinDML={defaults['min_dml']}, "
            f"MaxCLL={defaults['max_cll']}, MaxFALL={defaults['max_fall']}",
        )

    return final_metadata


def generate_extra_json(
    output_file: str, metadata: Dict[str, Any], trim_targets: List[int]
):
    """
    Generates the extra.json file for dovi_tool with direct mastering display metadata.

    Args:
        output_file: The path to write the JSON file.
        metadata: A dictionary with max_dml, min_dml, max_cll, and max_fall.
        trim_targets: A list of integer nits values for the trim pass.

    Returns:
        True on success, False on failure.
    """
    try:
        # Correctly calculate min_display_mastering_luminance
        min_display_luminance = int(float(metadata["min_dml"]) * 10000)

        json_content = {
            "target_nits": trim_targets,
            "level6": {
                "max_display_mastering_luminance": int(metadata["max_dml"]),
                "min_display_mastering_luminance": min_display_luminance,
                "max_content_light_level": int(metadata["max_cll"]),
                "max_frame_average_light_level": int(metadata["max_fall"]),
            },
        }

        with open(output_file, "w") as f:
            json.dump(json_content, f, indent=2)
        print("Generated extra.json content:")
        print(json.dumps(json_content, indent=2))
        return True
    except (IOError, TypeError) as e:
        print_color("red", f"Error: Failed to generate or write extra.json: {e}")
        return False


def extract_hdr10plus_metadata(input_file: str, temp_dir: str) -> Optional[str]:
    """
    Extracts HDR10+ metadata from a video file.

    Args:
        input_file: Path to the input video file.
        temp_dir: Path to the temporary working directory.

    Returns:
        Path to the extracted metadata JSON file, or None on failure.
    """
    print_color("green", "Step 1/2: Extracting HEVC video stream...")
    hevc_output = os.path.join(temp_dir, "video.hevc")
    ffmpeg_log = os.path.join(temp_dir, "ffmpeg_extract.log")
    cmd = [
        "ffmpeg",
        "-i",
        input_file,
        "-y",
        "-map",
        "0:v:0",
        "-c:v",
        "copy",
        "-bsf:v",
        "hevc_mp4toannexb",
        "-f",
        "hevc",
        hevc_output,
    ]
    if not run_command(cmd, ffmpeg_log):
        return None

    print_color("green", "Step 2/2: Extracting HDR10+ metadata from stream...")
    metadata_file = os.path.join(temp_dir, "hdr10plus_metadata.json")
    hdr10plus_log = os.path.join(temp_dir, "hdr10plus_tool.log")

    # Stream progress from hdr10plus_tool (non-blocking)
    cmd = ["hdr10plus_tool", "extract", "-i", hevc_output, "-o", metadata_file]
    try:
        with open(hdr10plus_log, "w") as log_file:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
            )
            last_line_time = time.time()
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                if line:
                    log_file.write(line)
                    log_file.flush()
                    # Print progress lines if they contain percent or step info
                    if re.search(r"(\d+\s*%|Progress)\b", line):
                        print(line.strip())
                    last_line_time = time.time()
                else:
                    # Periodic heartbeat every few seconds
                    if time.time() - last_line_time > 5:
                        print("...")
                        last_line_time = time.time()

        if process.returncode != 0:
            print_color("red", "hdr10plus_tool extraction failed. See log.")
            return None
    except FileNotFoundError:
        print_color("red", "hdr10plus_tool not found in PATH.")
        return None

    if os.path.exists(metadata_file) and os.path.getsize(metadata_file) > 0:
        print_color("green", "HDR10+ metadata extracted successfully.")
        return metadata_file
    else:
        print_color("red", "HDR10+ metadata extraction failed or file is empty.")
        return None


def generate_rpu(
    hdr_type: HdrFormat,
    temp_dir: str,
    peak_source: str,
    metadata_file: Optional[str] = None,
    measurements_file: Optional[str] = None,
) -> Optional[str]:
    """
    Generates the RPU.bin file using dovi_tool.

    Args:
        hdr_type: The HDR format being processed.
        temp_dir: The temporary working directory.
        peak_source: The peak source method for dovi_tool.
        metadata_file: Path to HDR10+ JSON metadata.
        measurements_file: Path to madVR measurements file.

    Returns:
        Path to the generated RPU.bin, or None on failure.
    """
    print_color("green", "Generating RPU file...")
    extra_json = os.path.join(temp_dir, "extra.json")
    rpu_bin = os.path.join(temp_dir, "RPU.bin")
    dovi_log = os.path.join(temp_dir, "dovi_tool_generate.log")

    cmd_base = ["dovi_tool", "generate", "-j", extra_json, "--rpu-out", rpu_bin]

    if hdr_type == HdrFormat.HDR10_PLUS:
        if not metadata_file:
            print_color("red", "Error: HDR10+ processing requires a metadata file.")
            return None
        cmd = cmd_base + [
            "--hdr10plus-json",
            metadata_file,
            "--hdr10plus-peak-source",
            peak_source,
        ]
    elif hdr_type == HdrFormat.HDR10_WITH_MEASUREMENTS:
        if not measurements_file:
            print_color("red", "Error: madVR processing requires a measurements file.")
            return None
        cmd = cmd_base + ["--madvr-file", measurements_file, "--use-custom-targets"]
    else:
        print_color(
            "red", f"Error: RPU generation not supported for HDR type {hdr_type.name}"
        )
        return None

    if run_command(cmd, dovi_log):
        print_color("green", "RPU.bin generated successfully.")
        return rpu_bin
    return None


def convert_file(input_file: str, temp_dir: str, args: argparse.Namespace):
    """
    Main conversion workflow for a single file.

    Args:
        input_file: Path to the input video file.
        temp_dir: Path to the temporary working directory.
        args: Parsed command-line arguments.
    """
    output_file = f"{os.path.splitext(input_file)[0]}.DV.mkv"
    if os.path.exists(output_file):
        print_color("yellow", f"Output file '{output_file}' already exists. Skipping.")
        return

    print_color("green", f"\n----- Processing: {os.path.basename(input_file)} -----")
    hdr_type = check_hdr_format(input_file)

    # Determine workflow based on HDR type
    measurements_file: Optional[str] = None
    hdr10plus_json: Optional[str] = None
    bl_source_file: str = input_file

    if hdr_type == HdrFormat.HDR10_PLUS:
        if not ensure_command("hdr10plus_tool"):
            return
        hdr10plus_json = extract_hdr10plus_metadata(input_file, temp_dir)
        if not hdr10plus_json:
            print_color("red", "Failed to extract HDR10+ metadata. Aborting.")
            return
    elif hdr_type == HdrFormat.HDR10_WITH_MEASUREMENTS:
        measurements_file = find_measurements_file(input_file)
        if not measurements_file:
            print_color("red", "Expected madVR measurements file not found.")
            return
        print_color("green", f"Using measurements file: {os.path.basename(measurements_file)}")
    elif hdr_type == HdrFormat.HDR10_UNSUPPORTED:
        print_color("yellow", "HDR10 detected without measurements. Running hdr_analyzer_mvp...")
        measurements_file = run_hdr_analyzer(input_file, temp_dir)
        if not measurements_file:
            return
    elif hdr_type == HdrFormat.HLG:
        print_color("yellow", "HLG detected. Converting to PQ, then generating measurements...")
        pq_path = convert_hlg_to_pq(input_file, temp_dir, args)
        if not pq_path:
            return
        bl_source_file = pq_path
        measurements_file = run_hdr_analyzer(bl_source_file, temp_dir)
        if not measurements_file:
            return
    else:
        print_color("red", f"Unsupported HDR format '{hdr_type.name}' for conversion. Skipping.")
        return

    # Validate measurements completeness if applicable (based on Details.txt when present)
    if measurements_file:
        details_path = find_details_file(input_file)
        if details_path and os.path.isfile(details_path):
            try:
                with open(details_path, "r", encoding="utf-8", errors="ignore") as f:
                    text = f.read()
                complete = re.search(r"Complete\s+flag:\s*1", text)
                if not complete:
                    print_color(
                        "yellow",
                        "Warning: madVR Details.txt indicates incomplete measurements (Complete flag != 1).",
                    )
                m_frames = re.search(r"Number\s+of\s+frames:\s*(\d+)", text)
                measured_frames = int(m_frames.group(1)) if m_frames else None
                file_frames = get_frame_count_from_mediainfo(input_file)
                if measured_frames and file_frames:
                    tolerance = max(100, int(file_frames * 0.02))
                    if abs(measured_frames - file_frames) > tolerance:
                        print_color(
                            "yellow",
                            f"Warning: Measurements frames ({measured_frames}) differ from file frames ({file_frames}).",
                        )
            except Exception:
                pass

    # Get static metadata for extra.json
    static_meta = get_static_metadata(input_file)
    print("Extracted Static Metadata:", static_meta)

    # Optionally derive trim targets from Details.txt
    trim_targets = args.trim_targets
    if args.trim_from_details:
        details_path = find_details_file(input_file)
        derived = parse_madvr_details_for_trims(details_path) if details_path else None
        if derived:
            trim_targets = derived
            print(f"Using trim targets from Details.txt: {trim_targets}")
        else:
            print_color("yellow", "Could not derive trim targets from Details.txt; using defaults.")

    # Generate extra.json
    extra_json_path = os.path.join(temp_dir, "extra.json")
    if not generate_extra_json(extra_json_path, static_meta, trim_targets):
        print_color(
            "red", "Failed to generate essential metadata. Aborting conversion."
        )
        return

    # Generate RPU based on prepared inputs
    rpu_bin_path = None
    if hdr10plus_json:
        rpu_bin_path = generate_rpu(
            HdrFormat.HDR10_PLUS, temp_dir, args.peak_source, metadata_file=hdr10plus_json
        )
    elif measurements_file:
        rpu_bin_path = generate_rpu(
            HdrFormat.HDR10_WITH_MEASUREMENTS,
            temp_dir,
            args.peak_source,
            measurements_file=measurements_file,
        )
    else:
        print_color("red", "No inputs available for RPU generation. Aborting.")
        return

    if not rpu_bin_path:
        print_color("red", "Failed to generate RPU.bin. Aborting conversion.")
        return

    # --- Final steps: inject and mux ---
    print_color("green", "Injecting RPU into base layer...")
    bl_hevc = os.path.join(temp_dir, "BL.hevc")
    bl_rpu_hevc = os.path.join(temp_dir, "BL_RPU.hevc")

    # Extract base layer from the prepared source (original or HLG->PQ)
    if not run_command(
        [
            "ffmpeg",
            "-i",
            bl_source_file,
            "-y",
            "-map",
            "0:v:0",
            "-c:v",
            "copy",
            "-f",
            "hevc",
            bl_hevc,
        ],
        os.path.join(temp_dir, "ffmpeg_bl_extract.log"),
    ):
        return

    # Inject RPU
    if not run_command(
        [
            "dovi_tool",
            "inject-rpu",
            "-i",
            bl_hevc,
            "--rpu-in",
            rpu_bin_path,
            "-o",
            bl_rpu_hevc,
        ],
        os.path.join(temp_dir, "dovi_inject.log"),
    ):
        return

    print_color("green", "Muxing final Dolby Vision file...")
    mkvmerge_cmd = [
        "mkvmerge",
        "-q",
        "-o",
        output_file,
    ]
    # Preserve chapters/tags by default; allow opt-out
    if args.drop_tags:
        mkvmerge_cmd.append("--no-global-tags")
    if args.drop_chapters:
        mkvmerge_cmd.append("--no-chapters")
    mkvmerge_cmd += [
        bl_rpu_hevc,
        "--no-video",
        os.path.abspath(input_file),
    ]
    if not run_command(mkvmerge_cmd, os.path.join(temp_dir, "mkvmerge.log")):
        return

    # Final validation and cleanup
    if os.path.exists(output_file):
        shutil.copystat(input_file, output_file)  # Preserve modification time
        print_color("green", f"âœ“ Success! Created: {os.path.basename(output_file)}")
    else:
        print_color("red", "Muxing failed, output file not created.")


def check_hdr_format(input_file: str) -> HdrFormat:
    """Checks the HDR format of the input file using mediainfo with robust fallbacks."""

    def infer_hdr_from_mi_json(video_track: Dict[str, Any]) -> Optional[HdrFormat]:
        # Gather candidates from explicit HDR fields
        hdr_fmt = str(video_track.get("HDR_Format", "")).upper()
        hdr_compat = str(video_track.get("HDR_Format_Compatibility", "")).upper()
        combined = f"{hdr_fmt} {hdr_compat}"
        if "2094" in combined or "HDR10+" in combined or "HDR10 PLUS" in combined:
            return HdrFormat.HDR10_PLUS
        if "HLG" in combined:
            return HdrFormat.HLG
        if "HDR10" in combined:
            return HdrFormat.HDR10_UNSUPPORTED

        # Scan other fields for transfer function hints
        for key, value in video_track.items():
            if not isinstance(value, str):
                continue
            val = value.upper()
            if "ARIB" in val and "B67" in val:
                return HdrFormat.HLG
            if "HLG" in val:
                return HdrFormat.HLG
            if "SMPTE" in val and "2084" in val:
                # PQ detected -> treat as HDR10 (non-plus) unless plus metadata found elsewhere
                return HdrFormat.HDR10_UNSUPPORTED
        return None

    def ffprobe_color_transfer(input_path: str) -> Optional[str]:
        try:
            if not shutil.which("ffprobe"):
                return None
            out = subprocess.check_output(
                [
                    "ffprobe",
                    "-v",
                    "error",
                    "-select_streams",
                    "v:0",
                    "-show_entries",
                    "stream=color_transfer",
                    "-of",
                    "default=nokey=1:noprint_wrappers=1",
                    input_path,
                ],
                text=True,
            ).strip()
            return out or None
        except subprocess.CalledProcessError:
            return None

    try:
        result = subprocess.check_output(
            [
                "mediainfo",
                "--Inform=Video;%HDR_Format%/%HDR_Format_Compatibility%",
                input_file,
            ],
            text=True,
            stderr=subprocess.PIPE,
            universal_newlines=True,
        )
        format_info = result.strip()

        measurements_file = find_measurements_file(input_file)

        # Primary, simple string-based detection
        if "SMPTE ST 2094 App 4" in format_info or "HDR10+" in format_info:
            print("Detected: HDR10+")
            return HdrFormat.HDR10_PLUS
        if "HLG" in format_info:
            print("Detected: HLG")
            return HdrFormat.HLG
        if "HDR10" in format_info or "PQ" in format_info or "ST 2084" in format_info:
            if measurements_file:
                print("Detected: HDR10 with madVR measurements file")
                return HdrFormat.HDR10_WITH_MEASUREMENTS
            print("Detected: HDR10 (no measurements)")
            return HdrFormat.HDR10_UNSUPPORTED

        # Fallback: use mediainfo JSON to infer
        mi_json = get_mediainfo_json_cached(input_file) or {}
        video_track = next(
            (
                t
                for t in mi_json.get("media", {}).get("track", [])
                if t.get("@type") == "Video"
            ),
            None,
        )
        if video_track:
            inferred = infer_hdr_from_mi_json(video_track)
            if inferred:
                if inferred == HdrFormat.HDR10_UNSUPPORTED and measurements_file:
                    print("Detected: HDR10 with madVR measurements file (inferred)")
                    return HdrFormat.HDR10_WITH_MEASUREMENTS
                print(f"Detected (inferred): {inferred.name}")
                return inferred

        # Fallback 2: ffprobe color_transfer
        color_trc = ffprobe_color_transfer(input_file)
        if color_trc:
            trc = color_trc.strip().lower()
            if "arib-std-b67" in trc or "hlg" in trc:
                print("Detected (ffprobe): HLG")
                return HdrFormat.HLG
            if "smpte2084" in trc or "pq" in trc:
                if measurements_file:
                    print("Detected (ffprobe): HDR10 with madVR measurements file")
                    return HdrFormat.HDR10_WITH_MEASUREMENTS
                print("Detected (ffprobe): HDR10 (no measurements)")
                return HdrFormat.HDR10_UNSUPPORTED

        # If still unknown, report unsupported with raw info string
        fmt_display = format_info if format_info else "/"
        print(f"Detected: Unsupported format ({fmt_display})")
        return HdrFormat.UNSUPPORTED
    except subprocess.CalledProcessError as e:
        print_color("red", f"Error checking HDR format with mediainfo: {e.stderr}")
        return HdrFormat.UNSUPPORTED


def get_frame_count_from_mediainfo(input_file: str) -> Optional[int]:
    """Try to obtain frame count from mediainfo JSON, with fallbacks."""
    mi_json = get_mediainfo_json_cached(input_file)
    if not mi_json:
        return None
    video_track = next(
        (
            t
            for t in mi_json.get("media", {}).get("track", [])
            if t.get("@type") == "Video"
        ),
        None,
    )
    if not video_track:
        return None
    # Direct frame count if available
    frame_count_str = video_track.get("FrameCount")
    if frame_count_str and str(frame_count_str).isdigit():
        return int(frame_count_str)
    # Fallback: duration (ms) and frame rate
    try:
        duration_ms = float(video_track.get("Duration", 0))
        frame_rate = float(video_track.get("FrameRate", 0))
        if duration_ms > 0 and frame_rate > 0:
            return int(round((duration_ms / 1000.0) * frame_rate))
    except Exception:
        pass
    return None


def main():
    """Main function to parse arguments and process files."""
    parser = argparse.ArgumentParser(
        description="A script to convert HDR10/HDR10+ files to Dolby Vision.",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument(
        "input",
        nargs="*",
        help="One or more input video files. If not provided, processes all .mkv files in the current directory.",
    )
    parser.add_argument(
        "--peak-source",
        choices=["max-scl-luminance", "histogram", "histogram99"],
        default="max-scl-luminance",
        help="Controls the --hdr10plus-peak-source flag in dovi_tool generate.\n"
        "  max-scl-luminance: (Default) Use max-scl from metadata.\n"
        "  histogram: Use the max value from histogram.\n"
        "  histogram99: Use the 99th percentile from histogram.",
    )
    parser.add_argument(
        "--trim-targets",
        type=str,
        default="100,600,1000",
        help=(
            "Comma-separated list of nits values for the Dolby Vision trim pass "
            "(e.g., '100,400,1000'). Used when Details.txt is unavailable or when "
            "--no-trim-from-details is specified."
        ),
    )
    parser.add_argument(
        "--trim-from-details",
        dest="trim_from_details",
        action="store_true",
        default=True,
        help=(
            "Derive target_nits automatically from madVR Details.txt (uses real display "
            "peak and maximum target nits). Enabled by default."
        ),
    )
    parser.add_argument(
        "--no-trim-from-details",
        dest="trim_from_details",
        action="store_false",
        help="Disable deriving target_nits from Details.txt and use --trim-targets instead.",
    )
    parser.add_argument(
        "--drop-chapters",
        action="store_true",
        help="Drop chapters in the output file (kept by default).",
    )
    parser.add_argument(
        "--drop-tags",
        action="store_true",
        help="Drop global tags in the output file (kept by default).",
    )
    parser.add_argument(
        "--hlg-crf",
        type=int,
        default=17,
        help="CRF to use when converting HLG to PQ (default: 17).",
    )
    parser.add_argument(
        "--hlg-preset",
        type=str,
        default="slow",
        help="x265 preset to use for HLG->PQ (default: slow).",
    )

    args = parser.parse_args()

    # Parse trim targets (possibly overridden later if --trim-from-details)
    try:
        args.trim_targets = [int(t.strip()) for t in args.trim_targets.split(",")]
    except ValueError:
        print_color(
            "red", "Error: --trim-targets must be a comma-separated list of integers."
        )
        sys.exit(1)

    check_dependencies()

    temp_dir = f"./mkvdolby_temp_{int(time.time())}"
    os.makedirs(temp_dir, exist_ok=True)
    atexit.register(cleanup, temp_dir)

    files_to_process = args.input
    if not files_to_process:
        files_to_process = glob.glob("*.mkv")
        if not files_to_process:
            print("No MKV files found in the current directory.")
            sys.exit(0)

    for file_path in files_to_process:
        if not os.path.isfile(file_path):
            print_color(
                "yellow", f"Warning: Input file not found, skipping: {file_path}"
            )
            continue
        if file_path.endswith(".DV.mkv"):
            print_color("yellow", f"Skipping already converted file: {file_path}")
            continue

        # Create a unique temp dir for each file to allow parallel runs in the future
        file_temp_dir = os.path.join(
            temp_dir, re.sub(r"[^a-zA-Z0-9]", "_", os.path.basename(file_path))
        )
        os.makedirs(file_temp_dir, exist_ok=True)

        convert_file(file_path, file_temp_dir, args)

    print("\nMKV Dolby Vision conversion process finished!")


if __name__ == "__main__":
    main()
